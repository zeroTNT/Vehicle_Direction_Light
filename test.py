import torch
from torchvision import models, transforms
from PIL import Image
import os
import argparse

# === åˆ†é¡å°æ‡‰ ===
class_names = ['no_signal', 'left_signal', 'right_signal']

# === æ¨¡å‹è¼‰å…¥ ===
def load_model(model_path):
    model = models.mobilenet_v2(pretrained=False)
    model.classifier[1] = torch.nn.Linear(model.last_channel, 3)
    model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))
    model.eval()
    return model

# === åœ–ç‰‡é è™•ç† ===
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# === æ¨è«–å–®å¼µåœ–ç‰‡ ===
def predict_image(model, image_path):
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0)  # å¢åŠ  batch ç¶­åº¦
    with torch.no_grad():
        outputs = model(image)
        _, predicted = torch.max(outputs, 1)
        label = class_names[predicted.item()]
    return label

# === ä¸»ç¨‹å¼ ===
if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--image', type=str, help='å–®å¼µåœ–ç‰‡æ¨è«–è·¯å¾‘')
    parser.add_argument('--dir', type=str, help='æ•´å€‹è³‡æ–™å¤¾æ¨è«–')
    parser.add_argument('--model', type=str, default='turn_signal_model.pth', help='æ¨¡å‹æª”è·¯å¾‘')
    args = parser.parse_args()

    model = load_model(args.model)

    if args.image:
        if not os.path.exists(args.image):
            print("âŒ æ‰¾ä¸åˆ°åœ–ç‰‡è·¯å¾‘ (--image)")
            exit(1)
        label = predict_image(model, args.image)
        print(f"âœ… åœ–ç‰‡ï¼š{args.image} â†’ æ¨è«–çµæœï¼š{label}")

    elif args.dir:
        if not os.path.exists(args.dir):
            print("âŒ æ‰¾ä¸åˆ°è³‡æ–™å¤¾è·¯å¾‘ (--dir)")
            exit(1)

        print(f"ğŸ“‚ æ‰¹æ¬¡æ¨è«–è³‡æ–™å¤¾ï¼š{args.dir}\n")
        for fname in os.listdir(args.dir):
            fpath = os.path.join(args.dir, fname)
            if not fname.lower().endswith(('.jpg', '.png', '.jpeg')):
                continue
            try:
                label = predict_image(model, fpath)
                print(f"  {fname:30s} â†’ {label}")
            except Exception as e:
                print(f"  âš ï¸ ç„¡æ³•è™•ç† {fname}: {e}")

    else:
        print("â—è«‹ä½¿ç”¨ --image æˆ– --dir åƒæ•¸æä¾›åœ–ç‰‡æˆ–è³‡æ–™å¤¾è·¯å¾‘")